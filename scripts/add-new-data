#! /usr/bin/env python

"""
A script to merge new sequences & associated metadata with
the current live dataset (present in ./data).
Author: James Hadfield <jhadfiel@fredhutch.org>
"""

import argparse
import os
from Bio import SeqIO
import sys
import csv
import re
from openpyxl import load_workbook
import shutil
from datetime import datetime

def parse_args():
    parser = argparse.ArgumentParser(description="Add new sequences & metadata to the previous collection of sequences & metadata.")
    return parser.parse_args()

def fatal(msg):
    print("ERROR: {}".format(msg))
    sys.exit(2)

def gather_files():
    def _ls (d, suffix):
        return [os.path.join(d, f) for f in os.listdir(d) if os.path.isfile(os.path.join(d, f)) if f.endswith(suffix) and not f.startswith("~$")]
    try:
        new_metadata = _ls("new_sequences", ".xlsx")
        new_sequences = _ls("new_sequences", ".fasta")
    except FileNotFoundError:
        return fatal("Please ensure both the \"data\" and \"new_sequences\" folders exist")

    data_metadata = os.path.join("data", "metadata.tsv")
    data_sequences = os.path.join("data", "sequences.fasta")
    if not os.path.isfile(data_metadata) or not os.path.isfile(data_sequences):
        return fatal("The data/metadata.tsv and/or data/sequences.fasta file are missing!")

    if not len(new_metadata):
        fatal("Please make sure there is at least one metadata file (ending in '.xlsx') inside the 'new_sequences' directory.")
    if not len(new_sequences):
        fatal("Please make sure there is at least one sequendes file (ending in '.fasta') inside the 'new_sequences' directory.")

    print("New metadata .xlsx files:\n\t" + "\n\t".join(new_metadata))
    print("New sequence FASTA files:\n\t" + "\n\t".join(new_sequences))
    print("")

    return {
        "data_metadata": data_metadata,
        "data_sequences": data_sequences,
        "new_metadata": new_metadata,
        "new_sequences": new_sequences
    }

def gather_sequences(ref_seqs, new_seqs):
    data = {}
    origin_file = {}
    errors = False
    new_seq_count = 0
    for fasta_path in [ref_seqs, *new_seqs]:
        for seq_record in SeqIO.parse(fasta_path, "fasta"):
            # turn 'BTB22545_S3_18FHV090_S4_DRC-2018-REF' into "BTB22545" as needed
            # NOTE: ignore "_outgroup"
            name = seq_record.id
            if not name.endswith("outgroup"):
                name = seq_record.id.split("_")[0]
            seq_record.id = name
            seq_record.description = seq_record.id
            if name in data:
                print("ERROR - the sequence {} (from {}) was already present in {}".format(name, fasta_path, origin_file[name]))
                errors = True
            else:
                origin_file[name] = fasta_path
                data[name] = seq_record
                if fasta_path != ref_seqs:
                    new_seq_count += 1
    if errors:
        fatal("Please remove those duplicate sequences!")
    print(f"Parsed {new_seq_count} new strains from FASTA files")
    return data


DATE_ERROR_MESSAGE = "Please add a date in YYYY-MM-DD format. For instance, '2019-09-16' or '2019-09-XX' if the exact day is not known or '2019-XX-XX' if only the year is known."
AMBIGUOUS_DATE = "XXXX-XX-XX"

def ensure_date(strain, excel_date, exit_on_error):
    """
    Given a openpyxl parsed cell value which conceptually corresponds to a date, do our best to represent it in
    YYYY-MM-DD format.

    Returns YYYY-MM-DD string or calls `fatal()` which will exit the program
    """
    def unknown_date(msg):
        return fatal(msg) if exit_on_error else AMBIGUOUS_DATE

    if excel_date is None:
        return unknown_date(f"There is no date provided for {strain!r}. {DATE_ERROR_MESSAGE}")

    if isinstance(excel_date, str):
        if excel_date == "" or excel_date == "?":
            return unknown_date(f"There is no date provided for {strain!r}. {DATE_ERROR_MESSAGE}")
        # attempt to parse as YYYY-MM-DD string
        match = re.search(r'^(\d{4})-(XX|\d\d)-(XX|\d\d)$', excel_date)
        if match:
            # some basic sanity checking -- YYYY-DD-MM dates and ambiguous months with provided days
            if (match.group(2)!="XX" and int(match.group(2)) > 12) or \
                (match.group(2)=="XX" and not match.group(3)=="XX"):
                return unknown_date(f"strain {strain!r} has date {excel_date!r} which doesn't seem correct. {DATE_ERROR_MESSAGE}")
            return excel_date
        # allow YYYY-MM dates
        if re.search(r'^(\d{4})-([\d]{2})$', excel_date):
            return f"{excel_date}-XX"
        # allow YYYY dates as well
        if re.search(r'^(\d{4})$', excel_date):
            return f"{excel_date}-XX-XX"

        return unknown_date(f"strain {strain!r} has date {excel_date!r} which is not in the correct format. {DATE_ERROR_MESSAGE}")

    if isinstance(excel_date, int) and excel_date>1980 and excel_date<=datetime.today().year:
        return f"{excel_date}-XX-XX"

    if isinstance(excel_date, datetime):
        # <https://openpyxl.readthedocs.io/en/stable/datetime.html>
        return f"{excel_date.year}-{excel_date.month:02}-{excel_date.day:02}"

    return unknown_date(f"strain {strain!r} has an unknown date {excel_date!r} (type: {type(excel_date)!r}) which is not in the correct format. {DATE_ERROR_MESSAGE}")


def fix_location(name):
    if name == "" or name == "?":
        return ""
    return "-".join([x.capitalize() for x in name.replace("-", "_").split("_")])

def fix_country(name):
    if name == "" or name == "?":
        return ""
    if name.upper() == "DRC":
        return "Democratic_Republic_of_the_Congo"
    if name.lower() == "democratic republic of the congo":
        return "Democratic_Republic_of_the_Congo"
    # e.g. Democratic_Republic_of_the_Congo
    return "_".join([x.capitalize() for x in name.replace("-", "_").split("_")])


def gather_metadata(ref_file, new_files):
    # tsv_header = ["strain", "date", "num_date", "location", "state", "region", "country", "study", "authors"]
    # tsv_data = []
    # strains = set()
    # lat_long_data = {}
    # for csv_path in args.metadataIn:

    data = {}
    origin_file = {}
    duplicates = False

    ## parse the data/metadata.tsv unchanged (i.e. if there are errors here they get fixed manually)
    with open(ref_file, "r") as fh:
        reader = csv.DictReader(fh, delimiter="\t")
        for row in reader:
            strain = row["strain"]
            origin_file[strain] = ref_file
            data[strain] = {
                "strain": strain,
                "virus": row["virus"],
                "date_symptom_onset": row["date_symptom_onset"],
                "date": row["date"],
                "health_zone": row["health_zone"],
                "province": row["province"],
                "country": row["country"],
                "authors": row["authors"]
            }
    
    new_strain_count = 0
    for fp in new_files:
        workbook = load_workbook(filename=fp)
        worksheet = workbook.active
        rows = worksheet.values # type: ignore
        if rows is None:
            print(f"The metadata file {fp} seemed to be empty!")
            return
        
        expected_header = ('strain', 'date_symptom_onset', 'date', 'health_zone', 'province', 'country', 'authors')
        header = next(rows)
        if header != expected_header:
            return fatal(f"The metadata file {fp} had unexpected columns! Please re-generate this file by copying the " +
                  "'data/template_metadata.xlsx' file into the 'new_sequences' folder and starting again.")

        for row in rows:
            strain = row[0]
            if strain is None: # empty rows - no problem!
                continue
            
            if strain in data:
                duplicates = True
                print("Error - {} is present in both {} and {}".format(strain, fp, origin_file[strain]))
                continue

            parsed_row = {
                "strain": strain,
                "virus": "ebola",
                "date_symptom_onset": ensure_date(strain, row[header.index("date_symptom_onset")], False),
                "date": ensure_date(strain, row[header.index("date")], True),
                "health_zone": fix_location(row[header.index("health_zone")]),
                "province": fix_location(row[header.index("province")]),
                "country": fix_country(row[header.index("country")]),
                "authors": row[header.index("authors")]
            }

            data[strain] = parsed_row
            new_strain_count+=1

    if duplicates:
        fatal("Please remove those duplicate metadata entries!")

    print(f"Parsed {new_strain_count} new strains from metadata")
    print("")
    return data

def ensure_matches(sequences, metadata):
    no_meta = [k for k in sequences.keys() if k not in metadata]
    no_seqs = [k for k in metadata.keys() if k not in sequences]
    if no_meta or no_seqs:
        fatal("Sequences & Metadata don't match :(\nSequences which don't have metadata: {}.\nMetadata without sequences: {}.".format(", ".join(no_meta), ", ".join(no_seqs)))
    print(f"After addition of new data we now have {len(metadata.keys())} genomes for analysis")
    print("")


def write_data(metadata_path, sequences_path, sequences, metadata):
    print("Writing (all) sequences & metadata into the data directory.")
    SeqIO.write([x for x in sequences.values()], sequences_path, "fasta")
    with open(metadata_path, "w") as fh:
        ## HEADER
        header = ["strain","virus","date_symptom_onset","date","health_zone","province","country","authors"]
        print("\t".join(header), file=fh)
        for _, value in metadata.items():
            print("\t".join([str(value[field]) for field in header]), file=fh)

def remove_new_sequences(paths):
    print("removing the files from 'new_sequences' that we've added to the data directory")
    for p in paths:
        try:
            os.remove(p)
        except PermissionError:
            print("Couldn't remove {} for some reason.".format(p))
            print("This is normally due to the file being open. Close it & rerun this script!")
            print("Please run the following command:")
            print("./scripts/clean-up")
    try:
        shutil.copyfile("./data/template_metadata.xlsx", './new_sequences/metadata.xlsx')
    except PermissionError:
        print("Couldn't copy the template file into the new_sequences folder")
        print("This is needed in order to have a template ready for the next batch of new sequences")
        print("Please copy it by typing the following command:")
        print("./scripts/clean-up")

if __name__ == "__main__":
    args = parse_args()
    files = gather_files()
    sequences = gather_sequences(files["data_sequences"], files["new_sequences"])
    metadata = gather_metadata(files["data_metadata"], files["new_metadata"])
    ensure_matches(sequences, metadata)
    write_data(files["data_metadata"], files["data_sequences"], sequences, metadata)
    remove_new_sequences([*files["new_sequences"], *files["new_metadata"]])
    print("\nSUCCESS\n")
